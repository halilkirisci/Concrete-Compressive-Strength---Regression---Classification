{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86879a39-00fb-4d4f-bcb0-05620175373a",
   "metadata": {},
   "source": [
    "# Concrete Compressive Strength - Regression & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c04cd-eee1-42f4-a591-8b670ebc75bb",
   "metadata": {},
   "source": [
    "<img src=\"https://ascentfuturetech.com/wp-content/uploads/2016/05/ascent-futuretech-pages-banner.png\" alt=\"Concrete Compressive Strength - Regand Cls\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c517d480-4c6c-4e7d-b974-9b3220c6d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63363877-bb68-44d8-a315-37580689e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_excel('Concrete_Data.xls')\n",
    "\n",
    "# Rename columns\n",
    "df.columns = ['Cement', 'Slag', 'FlyAsh', 'Water', 'Plasticizer', 'CoarseAgg', 'FineAgg', 'Age', 'Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e62c4a-3f64-4c0a-8eb9-085f08558e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare x and y\n",
    "X = df[['Cement', 'Slag', 'FlyAsh', 'Water', 'Plasticizer', 'CoarseAgg', 'FineAgg', 'Age']]\n",
    "\n",
    "y = df['Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9217aa5e-955e-4473-b28e-a3beab2d347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Cement       1030 non-null   float64\n",
      " 1   Slag         1030 non-null   float64\n",
      " 2   FlyAsh       1030 non-null   float64\n",
      " 3   Water        1030 non-null   float64\n",
      " 4   Plasticizer  1030 non-null   float64\n",
      " 5   CoarseAgg    1030 non-null   float64\n",
      " 6   FineAgg      1030 non-null   float64\n",
      " 7   Age          1030 non-null   int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 64.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7756bc-186d-4db1-a7e9-e73016f8edc7",
   "metadata": {},
   "source": [
    "# Problem 1 - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee072cb2-e804-4822-a2e5-d8d8841da0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f080e03-48df-489d-85ee-444193868197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'SVR': SVR(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'Polynomial Regression': make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88cb6725-1eec-44be-b46a-10fb9f2a3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d119d-1c86-4196-877e-3a344860f73d",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0db540c4-4051-4386-8cdf-f53655bf77cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 1709.9232 - val_loss: 344.9902\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 322.8960 - val_loss: 152.8686\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 160.1140 - val_loss: 118.0806\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 120.5515 - val_loss: 110.1887\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114.9667 - val_loss: 98.3359\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 97.1287 - val_loss: 93.5356\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 86.6749 - val_loss: 90.0204\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 86.2668 - val_loss: 87.2229\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 76.5311 - val_loss: 98.6733\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 78.1342 - val_loss: 82.6832\n",
      "Epoch 11/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 83.8274 - val_loss: 82.4709\n",
      "Epoch 12/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 71.9841 - val_loss: 76.9333\n",
      "Epoch 13/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 76.5300 - val_loss: 75.5613\n",
      "Epoch 14/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 70.3188 - val_loss: 74.3805\n",
      "Epoch 15/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 70.5523 - val_loss: 72.7753\n",
      "Epoch 16/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.8600 - val_loss: 71.4658\n",
      "Epoch 17/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 76.5293 - val_loss: 83.0503\n",
      "Epoch 18/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 69.3185 - val_loss: 74.0822\n",
      "Epoch 19/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 75.7643 - val_loss: 98.2140\n",
      "Epoch 20/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 77.1086 - val_loss: 69.3643\n",
      "Epoch 21/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 84.6949 - val_loss: 67.9432\n",
      "Epoch 22/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 75.1469 - val_loss: 66.4569\n",
      "Epoch 23/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 71.9072 - val_loss: 66.1762\n",
      "Epoch 24/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.9126 - val_loss: 65.8807\n",
      "Epoch 25/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 67.2892 - val_loss: 73.2613\n",
      "Epoch 26/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 67.6673 - val_loss: 65.2064\n",
      "Epoch 27/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.7447 - val_loss: 66.5258\n",
      "Epoch 28/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.3816 - val_loss: 70.8142\n",
      "Epoch 29/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.6772 - val_loss: 66.4852\n",
      "Epoch 30/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 65.5910 - val_loss: 114.5536\n",
      "Epoch 31/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 91.6643 - val_loss: 63.8208\n",
      "Epoch 32/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 61.9020 - val_loss: 64.5556\n",
      "Epoch 33/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.1196 - val_loss: 93.2532\n",
      "Epoch 34/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 75.1807 - val_loss: 61.2585\n",
      "Epoch 35/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.3001 - val_loss: 63.1573\n",
      "Epoch 36/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.3686 - val_loss: 68.6264\n",
      "Epoch 37/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 67.6019 - val_loss: 62.1607\n",
      "Epoch 38/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.6355 - val_loss: 64.1119\n",
      "Epoch 39/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.8203 - val_loss: 67.6495\n",
      "Epoch 40/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 66.0263 - val_loss: 61.4334\n",
      "Epoch 41/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.7451 - val_loss: 64.2183\n",
      "Epoch 42/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.3877 - val_loss: 62.4611\n",
      "Epoch 43/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.1805 - val_loss: 74.6407\n",
      "Epoch 44/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 62.0395 - val_loss: 76.1642\n",
      "Epoch 45/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.5490 - val_loss: 72.0687\n",
      "Epoch 46/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 65.1872 - val_loss: 60.9198\n",
      "Epoch 47/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 52.4768 - val_loss: 89.1543\n",
      "Epoch 48/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 75.6416 - val_loss: 74.2283\n",
      "Epoch 49/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.9883 - val_loss: 60.7358\n",
      "Epoch 50/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.0254 - val_loss: 63.5611\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Deep Learning Model Mean Squared Error: 50.81\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define deep learning model\n",
    "model_dl = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_dl.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train deep learning model\n",
    "model_dl.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate deep learning model\n",
    "y_pred_dl = model_dl.predict(X_test).flatten()\n",
    "mse_dl = mean_squared_error(y_test, y_pred_dl)\n",
    "print(f'Deep Learning Model Mean Squared Error: {mse_dl:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01222d89-b402-4c6b-af23-5fddff949ac4",
   "metadata": {},
   "source": [
    "# Proble 2-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba63b5f-002d-40ea-afb4-ada3e1413248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Cement   Slag  FlyAsh  Water  Plasticizer  CoarseAgg  FineAgg  Age  \\\n",
      "0      540.0    0.0     0.0  162.0          2.5     1040.0    676.0   28   \n",
      "1      540.0    0.0     0.0  162.0          2.5     1055.0    676.0   28   \n",
      "2      332.5  142.5     0.0  228.0          0.0      932.0    594.0  270   \n",
      "3      332.5  142.5     0.0  228.0          0.0      932.0    594.0  365   \n",
      "4      198.6  132.4     0.0  192.0          0.0      978.4    825.5  360   \n",
      "...      ...    ...     ...    ...          ...        ...      ...  ...   \n",
      "1025   276.4  116.0    90.3  179.6          8.9      870.1    768.3   28   \n",
      "1026   322.2    0.0   115.6  196.0         10.4      817.9    813.4   28   \n",
      "1027   148.5  139.4   108.6  192.7          6.1      892.4    780.0   28   \n",
      "1028   159.1  186.7     0.0  175.6         11.3      989.6    788.9   28   \n",
      "1029   260.9  100.5    78.3  200.6          8.6      864.5    761.5   28   \n",
      "\n",
      "       Strength  Green  ConcreteClass  \n",
      "0     79.986111    n/a  high-strength  \n",
      "1     61.887366    n/a     commercial  \n",
      "2     40.269535    n/a     commercial  \n",
      "3     41.052780    n/a     commercial  \n",
      "4     44.296075    n/a     commercial  \n",
      "...         ...    ...            ...  \n",
      "1025  44.284354  green     commercial  \n",
      "1026  31.178794  green     commercial  \n",
      "1027  23.696601  green    residential  \n",
      "1028  32.768036  green     commercial  \n",
      "1029  32.401235  green     commercial  \n",
      "\n",
      "[1030 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "def green_cls(s): \n",
    "    if (s.Slag + s.FlyAsh < 150.0) and (s.Plasticizer < 10.0):\n",
    "        return \"n/a\"\n",
    "    else:\n",
    "        return \"green\"\n",
    "\n",
    "def strength_cls(x):\n",
    "    if x < 17.0:\n",
    "        return \"non-structural\"\n",
    "    elif x < 28.0:\n",
    "        return \"residential\"\n",
    "    elif x < 70.0:\n",
    "        return \"commercial\"\n",
    "    else:\n",
    "        return \"high-strength\"\n",
    "\n",
    "df[\"Green\"] = df.apply(green_cls, axis=1)\n",
    "df[\"ConcreteClass\"] = df.Strength.apply(strength_cls)\n",
    "print(df)\n",
    "df.Plasticizer = df.Plasticizer.apply(lambda x: \"yes\" if x > 0 else \"no\")\n",
    "df.drop(\"Strength\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Convert categorical features to numeric\n",
    "df = pd.get_dummies(df, columns=['Plasticizer', 'Green'], drop_first=True)\n",
    "\n",
    "# Features and target\n",
    "X_class = df.drop('ConcreteClass', axis=1)\n",
    "y_class = df['ConcreteClass']\n",
    "\n",
    "# Split data\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c024cde-c06c-4d72-a26e-a7f16894a13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.80\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.88      0.90      0.89       133\n",
      " high-strength       1.00      0.33      0.50         6\n",
      "non-structural       0.74      0.81      0.78        32\n",
      "   residential       0.53      0.49      0.51        35\n",
      "\n",
      "      accuracy                           0.80       206\n",
      "     macro avg       0.79      0.63      0.67       206\n",
      "  weighted avg       0.80      0.80      0.80       206\n",
      "\n",
      "Decision Tree Accuracy: 0.84\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.92      0.90      0.91       133\n",
      " high-strength       1.00      0.50      0.67         6\n",
      "non-structural       0.92      0.72      0.81        32\n",
      "   residential       0.58      0.80      0.67        35\n",
      "\n",
      "      accuracy                           0.84       206\n",
      "     macro avg       0.86      0.73      0.77       206\n",
      "  weighted avg       0.87      0.84      0.85       206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.89\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.93      0.95      0.94       133\n",
      " high-strength       1.00      0.33      0.50         6\n",
      "non-structural       0.93      0.84      0.89        32\n",
      "   residential       0.71      0.77      0.74        35\n",
      "\n",
      "      accuracy                           0.89       206\n",
      "     macro avg       0.89      0.73      0.77       206\n",
      "  weighted avg       0.89      0.89      0.89       206\n",
      "\n",
      "SVM Accuracy: 0.65\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.65      1.00      0.78       133\n",
      " high-strength       0.00      0.00      0.00         6\n",
      "non-structural       0.00      0.00      0.00        32\n",
      "   residential       0.00      0.00      0.00        35\n",
      "\n",
      "      accuracy                           0.65       206\n",
      "     macro avg       0.16      0.25      0.20       206\n",
      "  weighted avg       0.42      0.65      0.51       206\n",
      "\n",
      "KNN Accuracy: 0.73\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.83      0.93      0.88       133\n",
      " high-strength       0.50      0.17      0.25         6\n",
      "non-structural       0.60      0.47      0.53        32\n",
      "   residential       0.37      0.31      0.34        35\n",
      "\n",
      "      accuracy                           0.73       206\n",
      "     macro avg       0.57      0.47      0.50       206\n",
      "  weighted avg       0.71      0.73      0.71       206\n",
      "\n",
      "Naive Bayes Accuracy: 0.68\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    commercial       0.89      0.73      0.80       133\n",
      " high-strength       0.31      0.67      0.42         6\n",
      "non-structural       0.53      0.81      0.64        32\n",
      "   residential       0.37      0.37      0.37        35\n",
      "\n",
      "      accuracy                           0.68       206\n",
      "     macro avg       0.52      0.64      0.56       206\n",
      "  weighted avg       0.73      0.68      0.69       206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Train and Evaluate Classification Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define models\n",
    "models_class = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models_class.items():\n",
    "    model.fit(X_train_class, y_train_class)\n",
    "    y_pred_class = model.predict(X_test_class)\n",
    "    accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "    print(f'{name} Accuracy: {accuracy:.2f}')\n",
    "    print(classification_report(y_test_class, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59ae5c-3de6-436e-bd38-e252b2fcbe1e",
   "metadata": {},
   "source": [
    "# Değerlendirme (Estimate) \n",
    "## Görülen sonuçlara göre Ramdom Forest en iyi genel performansı gösteriyor, yüksek doğruluk, precision ve recall değerleri ile en dengeli sonuçları sağlıyor.\n",
    "## According to the results, Random Forest shows the best overall performance, providing the most balanced results with high accuracy, precision and recall values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b934e4a-ca0d-45b4-bd81-f4f19b8c97f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
